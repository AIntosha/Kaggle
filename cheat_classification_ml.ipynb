{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# how to default Classification problem"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 1. Import libraries\n",
    "# 2. X, Y, shape\n",
    "# 3. test_split if needed\n",
    "\n",
    "### LogisticRegression\n",
    "# 4. logreg = LogisticRegression()\n",
    "# 5. logreg.fit(X, Y)\n",
    "# 6. Y_pred = logreg.predict(X)\n",
    "# 7. acc_logreg = logreg.score(X, Y)\n",
    "\n",
    "### NaiveBayes\n",
    "# 8. naivebayes = GaussianNB()\n",
    "# 9. naivebayes.fit(X, Y)\n",
    "# 10. Y_pred = naivebayes.predict(X)\n",
    "# 11. acc_naivebayes = naivebayes.score(X, Y)\n",
    "\n",
    "### SVM\n",
    "# 12. svm = SVC()\n",
    "# 13. svm.fit(X, Y)\n",
    "# 14. Y_pred = svm.predict(X)\n",
    "# 15. acc_svm = svm.score(X, Y)\n",
    "\n",
    "## universal code\n",
    "## universal code #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import libraries\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. X, Y, shape\n",
    "\n",
    "X = df.drop('target', axis=1)\n",
    "Y = df['target']\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. test_split if needed\n",
    "\n",
    "x_train, y_train, x_test, y_test = train_test_split(X, Y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# universal cell for classification\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "naive_bayes = GaussianNB()\n",
    "svc = SVC()\n",
    "linear_svc = LinearSVC()\n",
    "knn = KNeighborsClassifier()\n",
    "dec_tree = DecisionTreeClassifier()\n",
    "perceptron = Perceptron()\n",
    "sgd = SGDClassifier()\n",
    "random_forest =  RandomForestClassifier()\n",
    "\n",
    "logreg.fit(X, Y)\n",
    "Y_pred = logreg.predict(X)\n",
    "acc_logreg = logreg.score(X, Y)\n",
    "\n",
    "naive_bayes.fit(X, Y)\n",
    "Y_pred = naive_bayes.predict(X)\n",
    "acc_naive_bayes = naive_bayes.score(X, Y)\n",
    "\n",
    "svc.fit(X, Y)\n",
    "Y_pred = svc.predict(X)\n",
    "acc_svc = svc.score(X, Y)\n",
    "\n",
    "linear_svc.fit(X, Y)\n",
    "Y_pred = linear_svc.predict(X)\n",
    "acc_linear_svc = linear_svc.score(X, Y)\n",
    "\n",
    "knn.fit(X, Y)\n",
    "Y_pred = knn.predict(X)\n",
    "acc_knn = knn.score(X, Y)\n",
    "\n",
    "dec_tree.fit(X, Y)\n",
    "Y_pred = dec_tree.predict(X)\n",
    "acc_dec_tree = dec_tree.score(X, Y)\n",
    "\n",
    "perceptron.fit(X, Y)\n",
    "Y_pred = perceptron.predict(X)\n",
    "acc_perceptron = perceptron.score(X, Y)\n",
    "\n",
    "sgd.fit(X, Y)\n",
    "Y_pred = sgd.predict(X)\n",
    "acc_sgd = sgd.score(X, Y)\n",
    "\n",
    "random_forest.fit(X, Y)\n",
    "Y_pred = random_forest.predict(X)\n",
    "acc_random_forest = random_forest.score(X, Y)\n",
    "\n",
    "\n",
    "models = pd.DataFrame({\n",
    "    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n",
    "              'Random Forest', 'Naive Bayes', 'Perceptron', \n",
    "              'Stochastic Gradient Decent', 'Linear SVC', \n",
    "              'Decision Tree'],\n",
    "    'Score': [acc_svc, acc_knn, acc_logreg, \n",
    "              acc_random_forest, acc_naive_bayes, acc_perceptron, \n",
    "              acc_sgd, acc_linear_svc, acc_dec_tree]})\n",
    "models.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't assign to operator (<ipython-input-2-1b225b5c373b>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-1b225b5c373b>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    str(a)+str(b) = a+b\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m can't assign to operator\n"
     ]
    }
   ],
   "source": [
    "# universal cell for classification #2\n",
    "\n",
    "def universal():\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.svm import SVC, LinearSVC\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.linear_model import Perceptron\n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn import metrics\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    logreg = LogisticRegression()\n",
    "    naive_bayes = GaussianNB()\n",
    "    svc = SVC()\n",
    "    linear_svc = LinearSVC()\n",
    "    knn = KNeighborsClassifier()\n",
    "    dec_tree = DecisionTreeClassifier()\n",
    "    perceptron = Perceptron()\n",
    "    sgd = SGDClassifier()\n",
    "    random_forest =  RandomForestClassifier()\n",
    "\n",
    "    logreg.fit(X, Y)\n",
    "    Y_pred = logreg.predict(X)\n",
    "    acc_logreg = logreg.score(X, Y)\n",
    "\n",
    "    naive_bayes.fit(X, Y)\n",
    "    Y_pred = naive_bayes.predict(X)\n",
    "    acc_naive_bayes = naive_bayes.score(X, Y)\n",
    "\n",
    "    svc.fit(X, Y)\n",
    "    Y_pred = svc.predict(X)\n",
    "    acc_svc = svc.score(X, Y)\n",
    "\n",
    "    linear_svc.fit(X, Y)\n",
    "    Y_pred = linear_svc.predict(X)\n",
    "    acc_linear_svc = linear_svc.score(X, Y)\n",
    "\n",
    "    knn.fit(X, Y)\n",
    "    Y_pred = knn.predict(X)\n",
    "    acc_knn = knn.score(X, Y)\n",
    "\n",
    "    dec_tree.fit(X, Y)\n",
    "    Y_pred = dec_tree.predict(X)\n",
    "    acc_dec_tree = dec_tree.score(X, Y)\n",
    "\n",
    "    perceptron.fit(X, Y)\n",
    "    Y_pred = perceptron.predict(X)\n",
    "    acc_perceptron = perceptron.score(X, Y)\n",
    "\n",
    "    sgd.fit(X, Y)\n",
    "    Y_pred = sgd.predict(X)\n",
    "    acc_sgd = sgd.score(X, Y)\n",
    "\n",
    "    random_forest.fit(X, Y)\n",
    "    Y_pred = random_forest.predict(X)\n",
    "    acc_random_forest = random_forest.score(X, Y)\n",
    "\n",
    "\n",
    "    models = pd.DataFrame({\n",
    "        'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n",
    "                  'Random Forest', 'Naive Bayes', 'Perceptron', \n",
    "                  'Stochastic Gradient Decent', 'Linear SVC', \n",
    "                  'Decision Tree'],\n",
    "        'Score': [acc_svc, acc_knn, acc_logreg, \n",
    "                  acc_random_forest, acc_naive_bayes, acc_perceptron, \n",
    "                  acc_sgd, acc_linear_svc, acc_dec_tree]})\n",
    "    print(models.sort_values(by='Score', ascending=False))\n",
    "    print('-'*50)\n",
    "\n",
    "for i in range(1, 10):\n",
    "    x_train, y_train, x_test, y_test = train_test_split(X, Y, test_size=i/10, random_state=42)\n",
    "    print('-'*20, i/10)\n",
    "    universal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
